{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80359071-05a8-4d65-99f0-98217bc48b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "337e317c-3270-48da-b76f-353104dbd7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "489067a5-205f-40a0-8ccb-e5dca2802d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Hey this is Miss.Madhumitha . I am a Machine Learning Engineer, I work on NLP CNN. etc.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17f75432-ebd1-46c6-877f-f62636d6fb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey this is Miss.Madhumitha .\n",
      "I am a Machine Learning Engineer, I work on NLP CNN. etc.\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "290ed22e-f252-4ef7-b83a-4fae1b0085dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dr.Strange loves pav bhaji of India.', 'Hulk loves Thai']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sent_tokenize('Dr.Strange loves pav bhaji of India. Hulk loves Thai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e9aa410-7737-4fa5-9edf-96862fa712ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dr.Strange',\n",
       " 'loves',\n",
       " 'pav',\n",
       " 'bhaji',\n",
       " 'of',\n",
       " 'India',\n",
       " '.',\n",
       " 'Hulk',\n",
       " 'loves',\n",
       " 'Thai']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "word_tokenize('Dr.Strange loves pav bhaji of India. Hulk loves Thai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9d8d15e-e808-420c-b5ae-db9842de4346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey\n",
      "this\n",
      "is\n",
      "Miss.\n",
      "Madhumitha\n",
      ".\n",
      "I\n",
      "am\n",
      "a\n",
      "Machine\n",
      "Learning\n",
      "Engineer\n",
      ",\n",
      "I\n",
      "work\n",
      "on\n",
      "NLP\n",
      "CNN\n",
      ".\n",
      "etc\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank('en') # Blank processing pipeline\n",
    "\n",
    "doc = nlp(\"Hey this is Miss.Madhumitha . I am a Machine Learning Engineer, I work on NLP CNN. etc.\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9eb3b3a1-3efc-4412-ac2e-973cd58a9c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0815bf4-a06f-45c2-a4d8-fb8bf6730ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2a22c20-5686-4903-9b60-9f30611e8050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x20398445bb0>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x2038ecc7ef0>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x2038ea57a70>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x2039840ced0>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x20398407290>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x2038ea57680>)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03fc749d-1b6c-4c81-b241-8794276a48fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey | INTJ | hey\n",
      "this | PRON | this\n",
      "is | AUX | be\n",
      "Miss. | PROPN | Miss.\n",
      "Madhumitha | PROPN | Madhumitha\n",
      ". | PUNCT | .\n",
      "I | PRON | I\n",
      "am | AUX | be\n",
      "a | DET | a\n",
      "Machine | PROPN | Machine\n",
      "Learning | PROPN | Learning\n",
      "Engineer | PROPN | Engineer\n",
      ", | PUNCT | ,\n",
      "I | PRON | I\n",
      "work | VERB | work\n",
      "on | ADP | on\n",
      "NLP | PROPN | NLP\n",
      "CNN | PROPN | CNN\n",
      ". | PUNCT | .\n",
      "etc | X | etc\n",
      ". | PUNCT | .\n",
      "I | PRON | I\n",
      "ate | VERB | eat\n",
      "a | DET | a\n",
      "somosa | NOUN | somosa\n",
      ". | PUNCT | .\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Hey this is Miss.Madhumitha . I am a Machine Learning Engineer, I work on NLP CNN. etc. I ate a somosa.\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token, \"|\", token.pos_, \"|\", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47e64bbf-77bd-4055-ba48-6a4f47cfa53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Inc. | ORG | Companies, agencies, institutions, etc.\n",
      "45 billion | MONEY | Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I work at Google Inc. I have 45 billion\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, \"|\", ent.label_, \"|\", spacy.explain(ent.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a9a8f64-8785-4b40-b883-6e0429fb8528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I work at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Google Inc.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " I have \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    45 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style = \"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c34ea89-d60b-4413-b0fb-7b4fa5177fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ner']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "nlp.add_pipe(\"ner\", source=source_nlp)\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca92f7d3-52ee-40cf-aa85-c7bd6a7cc818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google | ORG | Companies, agencies, institutions, etc.\n",
      "45 billion | MONEY | Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I work at Google . I have 45 billion\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, \"|\", ent.label_, \"|\", spacy.explain(ent.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eed3e7e0-1dbe-42d1-a5b0-4fa56c1d3dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple | appl\n",
      "banana | banana\n",
      "car | car\n",
      "dog | dog\n",
      "cat | cat\n",
      "house | hous\n",
      "tree | tree\n",
      "book | book\n",
      "computer | comput\n",
      "chair | chair\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "words = [\"apple\", \"banana\", \"car\", \"dog\", \"cat\", \"house\", \"tree\", \"book\", \"computer\", \"chair\"]\n",
    "\n",
    "for word in words:\n",
    "    print(word, \"|\", stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f28fd77-5331-46cc-b5ff-5b744dd22c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bro | bro\n",
      "apple | apple\n",
      "banana | banana\n",
      "car | car\n",
      "better | well\n",
      "dog | dog\n",
      "eating | eat\n",
      "sleeping | sleep\n",
      "cat | cat\n",
      "house | house\n",
      "tree | tree\n",
      "book | book\n",
      "computer | computer\n",
      "chair | chair\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"bro apple banana car better dog eating sleeping cat house tree book computer chair\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token, \"|\", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ec7e229-c47b-4d13-824b-0b8a7441cc28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2cd7e5ff-4e7d-46c2-acc2-1793f80be4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bro | Brother\n",
      ", | ,\n",
      "what | what\n",
      "you | you\n",
      "doing | do\n",
      "Brah | Brother\n"
     ]
    }
   ],
   "source": [
    "ar = nlp.get_pipe('attribute_ruler')\n",
    "ar.add([[{\"TEXT\":\"Bro\"}], [{\"TEXT\":\"Brah\"}]] , {\"LEMMA\":\"Brother\"})\n",
    "\n",
    "doc = nlp(\"Bro, what you doing Brah\")\n",
    "for token in doc:\n",
    "    print(token, \"|\", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ff77def-c5f2-4e80-a171-2f12833115ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Brother'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0].lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a57847b-da39-4f6b-8fa6-f26b5b86b786",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
